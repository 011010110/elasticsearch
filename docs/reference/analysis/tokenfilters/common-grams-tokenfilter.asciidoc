[[analysis-common-grams-tokenfilter]]
=== Common Grams Token Filter

The `common_grams` token filter allows common words like `the` and `and` to be
indexed (and thus to be searchable), but makes phrase and other queries more efficient.

The <<analysis-stop-tokenfilter,Stopwords Token Filter>> removes common words
before indexing, which makes search more efficient. The downside is that
common words cannot be searched for.  Queries like `To be or not to be` or
`The Who` would return no matches.

At index time, the `common_grams` token filter indexes all words (including
common words) as unigrams , but it also creates bigrams out of any common word
and the word that precedes or follows it, e.g. `The rain in Spain falls
mainly` -> `[ the, the_rain, rain, rain_in, in, in_spain, spain, falls, mainly
]`.  These bigram combinations are much less common than the individual common
words.

At query time, the `common_grams` token filter drops any unigram which is also
the first part of a bigram -- `[ the_rain, rain_in, in_spain, spain, falls,
mainly ]`. This reduces the number of terms to search for and the number of
documents which might be possible matches, making the search much more
efficient.

The difference between index time and query time is controlled by the
`query_mode` parameter.

[float]
=== Configuration

The `common_grams` token filter accepts the following parameter:

[horizontal]
`common_words`::

    A list of common words, or a predefined list like `_english_`, as
    supported by the <<analysis-stop-tokenfilter,Stopwords Token Filter>>.

`common_words_path`::

    The path to a UTF8-encoded text file with one word per line, which must be
    present on every node. The path may be absolute or relative to the
    `config` directory.

`ignore_case`::

    If `true`, common words will be recognised regardless of their case.
    Defaults to `false`. Note, this doesn't affect the case of the emitted
    tokens.

`query_mode`::

    When `true`, unigrams that form the first part of a bigram are dropped.
    Defaults to `false`.

[float]
=== Example configuration

In this example, we configure the `common_grams` token filter to use the
`_english_` stopwords list.  We need two analyzers: one for index time and one
for query time:

[source,js]
----------------------------
PUT my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_index_analyzer": {
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "my_index_filter"
          ]
        },
        "my_search_analyzer": {
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "my_search_filter"
          ]
        }
      },
      "filter": {
        "my_index_filter": {
          "type": "common_grams",
          "common_words": "_english_",
          "query_mode": false
        },
        "my_search_filter": {
          "type": "common_grams",
          "common_words": "_english_",
          "query_mode": true
        }
      }
    }
  }
}

GET _cluster/health?wait_for_status=yellow

POST my_index/_analyze
{
  "analyzer": "my_index_analyzer",
  "text": "The rain in Spain falls mainly"
}
----------------------------
// CONSOLE

/////////////////////

[source,js]
----------------------------
{
  "tokens": [
    {
      "token": "the",
      "start_offset": 0,
      "end_offset": 3,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "the_rain",
      "start_offset": 0,
      "end_offset": 8,
      "type": "gram",
      "position": 0
    },
    {
      "token": "rain",
      "start_offset": 4,
      "end_offset": 8,
      "type": "<ALPHANUM>",
      "position": 1
    },
    {
      "token": "rain_in",
      "start_offset": 4,
      "end_offset": 11,
      "type": "gram",
      "position": 1
    },
    {
      "token": "in",
      "start_offset": 9,
      "end_offset": 11,
      "type": "<ALPHANUM>",
      "position": 2
    },
    {
      "token": "in_spain",
      "start_offset": 9,
      "end_offset": 17,
      "type": "gram",
      "position": 2
    },
    {
      "token": "spain",
      "start_offset": 12,
      "end_offset": 17,
      "type": "<ALPHANUM>",
      "position": 3
    },
    {
      "token": "falls",
      "start_offset": 18,
      "end_offset": 23,
      "type": "<ALPHANUM>",
      "position": 4
    },
    {
      "token": "mainly",
      "start_offset": 24,
      "end_offset": 30,
      "type": "<ALPHANUM>",
      "position": 5
    }
  ]
}
----------------------------
// TESTRESPONSE

/////////////////////


The `my_index_analyzer` produces the following terms:

[source,js]
----------------------------
[ the, the_rain, rain, rain_in, in, in_spain, spain, falls, mainly ]
----------------------------

Running the same request with the `my_search_analyzer`:

[source,js]
----------------------------
POST my_index/_analyze
{
  "analyzer": "my_search_analyzer",
  "text": "The rain in Spain falls mainly"
}
----------------------------
// CONSOLE
// TEST[continued]

/////////////////////

[source,js]
----------------------------
{
  "tokens": [
    {
      "token": "the_rain",
      "start_offset": 0,
      "end_offset": 8,
      "type": "gram",
      "position": 0
    },
    {
      "token": "rain_in",
      "start_offset": 4,
      "end_offset": 11,
      "type": "gram",
      "position": 1
    },
    {
      "token": "in_spain",
      "start_offset": 9,
      "end_offset": 17,
      "type": "gram",
      "position": 2
    },
    {
      "token": "spain",
      "start_offset": 12,
      "end_offset": 17,
      "type": "<ALPHANUM>",
      "position": 3
    },
    {
      "token": "falls",
      "start_offset": 18,
      "end_offset": 23,
      "type": "<ALPHANUM>",
      "position": 4
    },
    {
      "token": "mainly",
      "start_offset": 24,
      "end_offset": 30,
      "type": "<ALPHANUM>",
      "position": 5
    }
  ]
}
----------------------------
// TESTRESPONSE

/////////////////////

produces the following terms:

[source,js]
----------------------------
[ the_rain, rain_in, in_spain, spain, falls, mainly ]
----------------------------

TIP: A field which uses the `common_grams` token filter to index unigrams can
also be queried with an analyzer that just emits unigrams, like the `standard`
analyzer. This is not as efficient as using a `common_grams`-based analyzer,
but it will match documents where the order of common words is different from
that used in the query.

than in the document.

